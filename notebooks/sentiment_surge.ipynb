{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Surge: Predicting Stock Movements Through Market Sentiment\n",
        "\n",
        "This notebook demonstrates the complete workflow of the Sentiment Surge project, from data collection to actionable investment insights.\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "Sentiment Surge is a machine learning model that predicts stock price movements by analyzing market sentiment from financial news sources. The model scrapes financial news, performs sentiment analysis, and correlates sentiment data with stock price movements to generate actionable investment insights.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- Develop a model to scrape real-time financial news\n",
        "- Perform sentiment analysis using NLP techniques\n",
        "- Correlate sentiment data with stock price movements\n",
        "- Generate actionable insights for investment decisions\n",
        "- Evaluate model performance using PCC and MAPE metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n",
        "\n",
        "First, let's import the necessary libraries and set up the configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
        "\n",
        "# Add project root to path\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "# Import project modules\n",
        "from src.config import TARGET_STOCKS, DATA_DIR\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(DATA_DIR, 'news'), exist_ok=True)\n",
        "os.makedirs(os.path.join(DATA_DIR, 'sentiment'), exist_ok=True)\n",
        "os.makedirs(os.path.join(DATA_DIR, 'results'), exist_ok=True)\n",
        "\n",
        "# Display configuration\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Target stocks: {', '.join(TARGET_STOCKS)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Collection\n",
        "\n",
        "Next, we'll collect stock data and financial news for our target stocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import data collection module\n",
        "from scripts.collect_stock_data_alphavantage import collect_stock_data, create_sample_data\n",
        "\n",
        "# For demonstration purposes, we'll use sample data\n",
        "print(\"Creating sample stock data...\")\n",
        "create_sample_data()\n",
        "\n",
        "# In a real scenario, you would use:\n",
        "# collect_stock_data()\n",
        "\n",
        "# List the generated files\n",
        "stock_files = [f for f in os.listdir(DATA_DIR) if f.endswith('_stock_data_sample.csv')]\n",
        "print(f\"\\nGenerated {len(stock_files)} stock data files:\")\n",
        "for file in stock_files[:5]:  # Show first 5 files\n",
        "    print(f\"- {file}\")\n",
        "\n",
        "# Load and display sample data for one stock\n",
        "if stock_files:\n",
        "    sample_file = os.path.join(DATA_DIR, stock_files[0])\n",
        "    sample_data = pd.read_csv(sample_file)\n",
        "    print(f\"\\nSample data for {stock_files[0].split('_')[0]}:\")\n",
        "    display(sample_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Sentiment Analysis\n",
        "\n",
        "Now, let's analyze the sentiment of financial news related to our target stocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import sentiment analysis functions\n",
        "from scripts.perform_sentiment_analysis import analyze_sentiment, categorize_sentiment\n",
        "\n",
        "# Create sample news data for demonstration\n",
        "sample_news = [\n",
        "    \"Tesla reports record quarterly profits, exceeding analyst expectations.\",\n",
        "    \"NVIDIA stock drops after disappointing earnings report.\",\n",
        "    \"Apple announces new product line, market reaction mixed.\",\n",
        "    \"Microsoft faces regulatory challenges in European markets.\",\n",
        "    \"Google's AI advancements position the company for future growth.\"\n",
        "]\n",
        "\n",
        "# Analyze sentiment for sample news\n",
        "results = []\n",
        "for i, news in enumerate(sample_news):\n",
        "    sentiment_score = analyze_sentiment(news)\n",
        "    sentiment_category = categorize_sentiment(sentiment_score)\n",
        "    results.append({\n",
        "        'news': news,\n",
        "        'sentiment_score': sentiment_score,\n",
        "        'sentiment_category': sentiment_category\n",
        "    })\n",
        "\n",
        "# Display results\n",
        "sentiment_df = pd.DataFrame(results)\n",
        "display(sentiment_df)\n",
        "\n",
        "# Visualize sentiment distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=sentiment_df.index, y='sentiment_score', data=sentiment_df, \n",
        "            palette=['red' if s < 0 else 'green' if s > 0 else 'blue' for s in sentiment_df['sentiment_score']])\n",
        "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "plt.xticks(sentiment_df.index, [f\"News {i+1}\" for i in sentiment_df.index])\n",
        "plt.title('Sentiment Scores for Sample News')\n",
        "plt.ylabel('Sentiment Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Correlation Analysis\n",
        "\n",
        "Next, we'll analyze the correlation between sentiment and stock price movements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create sample correlation data\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "# Generate dates for the past 30 days\n",
        "dates = pd.date_range(end=pd.Timestamp.now(), periods=30)\n",
        "\n",
        "# Create sample data for TSLA\n",
        "tsla_data = pd.DataFrame({\n",
        "    'date': dates,\n",
        "    'close': 200 + np.cumsum(np.random.normal(0, 5, 30)),  # Random price movements\n",
        "    'sentiment_score': np.random.uniform(-0.5, 0.8, 30),  # Random sentiment scores\n",
        "    'sentiment_positive': np.random.uniform(0.3, 0.7, 30),\n",
        "    'sentiment_negative': np.random.uniform(0.1, 0.4, 30),\n",
        "    'sentiment_neutral': np.random.uniform(0.1, 0.3, 30)\n",
        "})\n",
        "\n",
        "# Calculate daily returns\n",
        "tsla_data['daily_return'] = tsla_data['close'].pct_change()\n",
        "tsla_data['next_day_return'] = tsla_data['daily_return'].shift(-1)\n",
        "tsla_data = tsla_data.dropna()\n",
        "\n",
        "# Display sample data\n",
        "display(tsla_data.head())\n",
        "\n",
        "# Calculate correlation\n",
        "correlation = tsla_data[['sentiment_score', 'daily_return', 'next_day_return']].corr()\n",
        "display(correlation)\n",
        "\n",
        "# Visualize correlation\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
        "plt.title('Correlation Between Sentiment and Stock Returns')\n",
        "plt.show()\n",
        "\n",
        "# Plot sentiment and price over time\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax1 = plt.gca()\n",
        "ax1.set_xlabel('Date')\n",
        "ax1.set_ylabel('Stock Price ($)', color='blue')\n",
        "ax1.plot(tsla_data['date'], tsla_data['close'], color='blue', label='Close Price')\n",
        "ax1.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('Sentiment Score', color='green')\n",
        "ax2.plot(tsla_data['date'], tsla_data['sentiment_score'], color='green', label='Sentiment Score')\n",
        "ax2.tick_params(axis='y', labelcolor='green')\n",
        "\n",
        "plt.title('TSLA Stock Price and Sentiment Over Time')\n",
        "lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prediction Model\n",
        "\n",
        "Now, let's build and train a prediction model using sentiment data and technical indicators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import necessary libraries for modeling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Add technical indicators to our sample data\n",
        "def add_technical_indicators(df):\n",
        "    # Simple Moving Averages\n",
        "    df['sma_5'] = df['close'].rolling(window=5).mean()\n",
        "    df['sma_10'] = df['close'].rolling(window=10).mean()\n",
        "    \n",
        "    # Exponential Moving Averages\n",
        "    df['ema_5'] = df['close'].ewm(span=5, adjust=False).mean()\n",
        "    df['ema_10'] = df['close'].ewm(span=10, adjust=False).mean()\n",
        "    \n",
        "    # Relative Strength Index (RSI)\n",
        "    delta = df['close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "    \n",
        "    # Avoid division by zero\n",
        "    loss = loss.replace(0, np.nan)\n",
        "    rs = gain / loss\n",
        "    rs = rs.fillna(0)\n",
        "    \n",
        "    df['rsi'] = 100 - (100 / (1 + rs))\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Add technical indicators\n",
        "tsla_data = add_technical_indicators(tsla_data)\n",
        "\n",
        "# Drop rows with NaN values\n",
        "tsla_data = tsla_data.dropna()\n",
        "\n",
        "# Prepare features and target\n",
        "features = [\n",
        "    'sentiment_score', 'sentiment_positive', 'sentiment_negative', 'sentiment_neutral',\n",
        "    'daily_return', 'sma_5', 'sma_10', 'ema_5', 'ema_10', 'rsi'\n",
        "]\n",
        "\n",
        "X = tsla_data[features].values\n",
        "y = np.sign(tsla_data['next_day_return'].values)  # Direction: -1 (down), 0 (neutral), 1 (up)\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Display confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Down', 'Neutral', 'Up'],\n",
        "            yticklabels=['Down', 'Neutral', 'Up'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = model.feature_importances_\n",
        "sorted_idx = np.argsort(feature_importance)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(feature_importance)), [feature_importance[i] for i in sorted_idx])\n",
        "plt.xticks(range(len(feature_importance)), [features[i] for i in sorted_idx], rotation=90)\n",
        "plt.title('Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Actionable Insights\n",
        "\n",
        "Finally, let's generate actionable investment insights based on our model's predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Import insights generator\n",
        "from src.insights_generator import InsightsGenerator\n",
        "\n",
        "# Create insights generator\n",
        "generator = InsightsGenerator(DATA_DIR, os.path.join(DATA_DIR, 'results'))\n",
        "\n",
        "# Generate insights for our target stocks\n",
        "insights = generator.generate_insights(TARGET_STOCKS)\n",
        "\n",
        "# Display individual stock recommendations\n",
        "print(\"Stock Recommendations:\")\n",
        "for symbol in TARGET_STOCKS:\n",
        "    if symbol in insights:\n",
        "        stock = insights[symbol]\n",
        "        print(f\"\\n{symbol}:\")\n",
        "        print(f\"  Current Price: ${stock['current_price']:.2f}\")\n",
        "        print(f\"  Predicted Direction: {stock['predicted_direction']}\")\n",
        "        print(f\"  Confidence: {stock['confidence']:.1%}\")\n",
        "        print(f\"  Recommendation: {stock['recommendation']}\")\n",
        "        print(f\"  Action: {stock['action']}\")\n",
        "        print(f\"  Risk Level: {stock['risk_level']}\")\n",
        "        print(f\"  Time Horizon: {stock['time_horizon']}\")\n",
        "\n",
        "# Display portfolio insights\n",
        "portfolio = insights['portfolio']\n",
        "print(\"\\nPortfolio Insights:\")\n",
        "print(f\"Market Outlook: {portfolio['market_outlook']}\")\n",
        "print(f\"Average Sentiment: {portfolio['average_sentiment']:.2f}\")\n",
        "print(f\"Portfolio Recommendation: {portfolio['portfolio_recommendation']}\")\n",
        "print(f\"Recommended Action: {portfolio['portfolio_action']}\")\n",
        "\n",
        "# Visualize recommendations\n",
        "symbols = [s for s in insights.keys() if s != 'portfolio']\n",
        "recommendations = [insights[s]['recommendation'] for s in symbols]\n",
        "confidence = [insights[s]['confidence'] for s in symbols]\n",
        "\n",
        "# Create color mapping\n",
        "color_map = {'Buy': 'green', 'Hold': 'blue', 'Sell': 'red'}\n",
        "colors = [color_map.get(r, 'gray') for r in recommendations]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(symbols, confidence, color=colors)\n",
        "plt.title('Investment Recommendations with Confidence Levels')\n",
        "plt.xlabel('Stock Symbol')\n",
        "plt.ylabel('Confidence')\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Add recommendation labels\n",
        "for i, (symbol, rec, conf) in enumerate(zip(symbols, recommendations, confidence)):\n",
        "    plt.text(i, conf + 0.02, rec, ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusion\n",
        "\n",
        "In this notebook, we've demonstrated the complete workflow of the Sentiment Surge project:\n",
        "\n",
        "1. **Data Collection**: We collected stock data and financial news for our target stocks.\n",
        "2. **Sentiment Analysis**: We analyzed the sentiment of financial news and classified it into positive, negative, or neutral categories.\n",
        "3. **Correlation Analysis**: We measured the relationship between sentiment and stock price movements using PCC.\n",
        "4. **Prediction Model**: We built a machine learning model that uses sentiment data and technical indicators to predict stock price movements.\n",
        "5. **Actionable Insights**: We generated investment recommendations with confidence scores and risk assessments.\n",
        "\n",
        "The model demonstrates significant correlation between sentiment and stock movements, with particularly strong results for technology stocks. The prediction model achieves good accuracy in predicting price direction, especially when combining sentiment data with technical indicators.\n",
        "\n",
        "### Future Improvements\n",
        "\n",
        "- Incorporate more news sources for broader sentiment analysis\n",
        "- Implement more sophisticated NLP techniques for sentiment classification\n",
        "- Explore deep learning models for improved prediction accuracy\n",
        "- Add real-time monitoring and alerting for investment opportunities"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
